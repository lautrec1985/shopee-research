import streamlit as st
import httpx
import asyncio
import csv
import io
import re
import time
from typing import Optional
import pandas as pd

st.set_page_config(
    page_title="Shopee Research Tool",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=DM+Mono:wght@400;500&display=swap');

html, body, [class*="css"] {
    font-family: 'DM Mono', monospace;
}

.main-header {
    background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%);
    padding: 2rem;
    border-radius: 12px;
    margin-bottom: 2rem;
    border: 1px solid #e94560;
}

.metric-card {
    background: #1a1a2e;
    border: 1px solid #0f3460;
    border-radius: 8px;
    padding: 1rem;
    text-align: center;
}

.preferred-badge {
    background: #f0a500;
    color: #000;
    padding: 2px 8px;
    border-radius: 4px;
    font-size: 0.75rem;
    font-weight: bold;
}

.stButton > button {
    background: #e94560 !important;
    color: white !important;
    border: none !important;
    border-radius: 8px !important;
    font-family: 'DM Mono', monospace !important;
    font-weight: 500 !important;
}

.stButton > button:hover {
    background: #c73652 !important;
}

div[data-testid="stTab"] {
    font-family: 'DM Mono', monospace;
}
</style>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Constants
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SHOPEE_BASE = "https://shopee.co.jp"
SHOPEE_API = "https://shopee.co.jp/api/v4"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
    "Referer": "https://shopee.co.jp/",
    "Accept": "application/json",
    "X-API-SOURCE": "pc",
    "X-Requested-With": "XMLHttpRequest",
}

SHOPEE_CATEGORIES = {
    "Electronicsï¼ˆé›»å­æ©Ÿå™¨ï¼‰": 11044906,
    "Fashionï¼ˆãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ï¼‰": 11044914,
    "Home & Livingï¼ˆãƒ›ãƒ¼ãƒ ï¼‰": 11044916,
    "Sports & Outdoorsï¼ˆã‚¹ãƒãƒ¼ãƒ„ï¼‰": 11044932,
    "Toys & Gamesï¼ˆãŠã‚‚ã¡ã‚ƒï¼‰": 11044924,
    "Baby & Kidsï¼ˆãƒ™ãƒ“ãƒ¼ï¼‰": 11044956,
    "Health & Beautyï¼ˆç¾å®¹ï¼‰": 11044970,
    "Food & Beveragesï¼ˆé£Ÿå“ï¼‰": 11044972,
    "Books & Stationeryï¼ˆæœ¬ï¼‰": 11044982,
    "Automotiveï¼ˆè‡ªå‹•è»Šï¼‰": 11044998,
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# API Functions
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def shopee_search(keyword: str, page: int = 0) -> dict:
    params = {
        "by": "sales",
        "keyword": keyword,
        "limit": 60,
        "newest": page * 60,
        "order": "desc",
        "page_type": "search",
        "scenario": "PAGE_GLOBAL_SEARCH",
        "version": 2,
    }
    try:
        with httpx.Client(headers=HEADERS, timeout=20) as client:
            r = client.get(f"{SHOPEE_API}/search/search_items/", params=params)
            return r.json() if r.status_code == 200 else {}
    except Exception as e:
        st.warning(f"API ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def shopee_category_search(category_id: int, page: int = 0) -> dict:
    params = {
        "by": "sales",
        "limit": 60,
        "newest": page * 60,
        "order": "desc",
        "catid": category_id,
        "version": 2,
    }
    try:
        with httpx.Client(headers=HEADERS, timeout=20) as client:
            r = client.get(f"{SHOPEE_API}/search/search_items/", params=params)
            return r.json() if r.status_code == 200 else {}
    except Exception as e:
        st.warning(f"API ã‚¨ãƒ©ãƒ¼: {e}")
        return {}

def get_shop_info(shop_id: int) -> dict:
    try:
        with httpx.Client(headers=HEADERS, timeout=20) as client:
            r = client.get(f"{SHOPEE_API}/shop/get_shop_detail/", params={"shopid": shop_id})
            return r.json().get("data", {}) if r.status_code == 200 else {}
    except:
        return {}

def get_shop_items(shop_id: int, page: int = 0, limit: int = 100) -> list:
    params = {
        "shopid": shop_id,
        "sort_by": "sales",
        "order": "desc",
        "limit": limit,
        "offset": page * limit,
        "filter_sold_out": 0,
    }
    try:
        with httpx.Client(headers=HEADERS, timeout=20) as client:
            r = client.get(f"{SHOPEE_API}/recommend/recommend_items/", params=params)
            return r.json().get("items", []) if r.status_code == 200 else []
    except:
        return []

def search_asin(title: str) -> Optional[str]:
    clean = re.sub(r'[ã€ã€‘ã€Œã€\[\]ï¼ˆï¼‰()]', ' ', title)
    clean = ' '.join(clean.split()[:8])
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 Chrome/120.0.0.0 Safari/537.36",
            "Accept-Language": "ja-JP,ja;q=0.9",
        }
        with httpx.Client(headers=headers, timeout=15, follow_redirects=True) as client:
            r = client.get("https://www.amazon.co.jp/s", params={"k": clean})
            if r.status_code == 200:
                asins = re.findall(r'/dp/([A-Z0-9]{10})', r.text)
                if asins:
                    return asins[0]
    except:
        pass
    return None

def parse_item(item: dict, japan_only: bool) -> Optional[dict]:
    try:
        basic = item.get("item_basic", {})
        location = basic.get("shop_location", "")
        if japan_only and location != "Japan":
            return None
        return {
            "shop_name": basic.get("shop_name", ""),
            "shop_id": basic.get("shopid", 0),
            "shop_url": f"{SHOPEE_BASE}/{basic.get('shop_name', '')}",
            "item_id": basic.get("itemid", 0),
            "item_url": f"{SHOPEE_BASE}/{basic.get('shop_name', '')}-i.{basic.get('shopid', '')}.{basic.get('itemid', '')}",
            "title": basic.get("name", ""),
            "sold": basic.get("historical_sold", 0),
            "price": basic.get("price", 0) / 100000,
            "is_preferred": basic.get("is_preferred_plus_seller", False),
            "location": location,
        }
    except:
        return None

def to_csv(df: pd.DataFrame) -> bytes:
    return df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Header
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("""
<div class="main-header">
    <h1 style="color:#e94560; margin:0; font-size:1.8rem;">ğŸ›ï¸ Shopee Research Tool</h1>
    <p style="color:#a0aec0; margin:0.5rem 0 0 0; font-size:0.85rem;">shopee.co.jp ã‚»ãƒ©ãƒ¼ãƒ»å•†å“ãƒªã‚µãƒ¼ãƒè‡ªå‹•åŒ–</p>
</div>
""", unsafe_allow_html=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Tabs
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab1, tab2, tab3, tab4 = st.tabs([
    "â‘  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢",
    "â‘¡ ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢",
    "â‘¢ å°‚é–€åº—ãƒªã‚µãƒ¼ãƒ",
    "â‘£ ASINæŠ½å‡º",
])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘  ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab1:
    st.subheader("ğŸ”¤ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰å£²ã‚Œã¦ã‚‹åº—èˆ—ã‚’æ¢ã™")

    col1, col2 = st.columns([2, 1])
    with col1:
        keyword = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹±èªï¼‰", placeholder="ä¾‹: golf club, baby toy, kitchen")
    with col2:
        pages = st.number_input("æ¤œç´¢ãƒšãƒ¼ã‚¸æ•°", min_value=1, max_value=20, value=3)

    col3, col4, col5 = st.columns(3)
    with col3:
        japan_only = st.toggle("ğŸ‡¯ğŸ‡µ æ—¥æœ¬ã‚»ãƒ©ãƒ¼ã®ã¿", value=True)
    with col4:
        preferred_only = st.toggle("â­ Preferredã®ã¿", value=False)
    with col5:
        min_sold = st.number_input("æœ€ä½Soldæ•°", min_value=0, value=1)

    min_products = st.number_input("æœ€ä½å•†å“æ•°ï¼ˆ0=åˆ¶é™ãªã—ï¼‰", min_value=0, value=0)

    if st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", key="btn1"):
        if not keyword:
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            shops = {}
            items_list = []
            progress = st.progress(0, text="æ¤œç´¢ä¸­...")

            for page in range(pages):
                progress.progress((page + 1) / pages, text=f"ãƒšãƒ¼ã‚¸ {page+1}/{pages} æ¤œç´¢ä¸­...")
                data = shopee_search(keyword, page)
                raw = data.get("items", [])
                if not raw:
                    break

                for item in raw:
                    parsed = parse_item(item, japan_only)
                    if not parsed:
                        continue
                    if parsed["sold"] < min_sold:
                        continue
                    if preferred_only and not parsed["is_preferred"]:
                        continue

                    items_list.append(parsed)
                    sid = parsed["shop_id"]
                    if sid not in shops:
                        shops[sid] = {
                            "åº—èˆ—å": parsed["shop_name"],
                            "åº—èˆ—URL": parsed["shop_url"],
                            "Preferred": "â­ YES" if parsed["is_preferred"] else "NO",
                            "åœ°åŸŸ": parsed["location"],
                            "ç·Soldæ•°": 0,
                            "å•†å“æ•°": 0,
                        }
                    shops[sid]["ç·Soldæ•°"] += parsed["sold"]
                    shops[sid]["å•†å“æ•°"] += 1

                time.sleep(0.5)

            progress.empty()

            shop_list = list(shops.values())
            if min_products > 0:
                shop_list = [s for s in shop_list if s["å•†å“æ•°"] >= min_products]

            shop_list.sort(key=lambda x: x["ç·Soldæ•°"], reverse=True)

            st.success(f"âœ… åº—èˆ—æ•°: {len(shop_list)} ä»¶ / å•†å“æ•°: {len(items_list)} ä»¶")

            if shop_list:
                df = pd.DataFrame(shop_list)
                st.dataframe(df, use_container_width=True)
                st.download_button(
                    "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=to_csv(df),
                    file_name=f"shopee_keyword_{keyword}.csv",
                    mime="text/csv"
                )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¡ ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab2:
    st.subheader("ğŸ“‚ ã‚«ãƒ†ã‚´ãƒªã‹ã‚‰å•†å“ã‚’æ¢ã™")

    cat_label = st.selectbox("ã‚«ãƒ†ã‚´ãƒª", list(SHOPEE_CATEGORIES.keys()))
    cat_id = SHOPEE_CATEGORIES[cat_label]

    col1, col2, col3 = st.columns(3)
    with col1:
        japan_only2 = st.toggle("ğŸ‡¯ğŸ‡µ æ—¥æœ¬ã‚»ãƒ©ãƒ¼ã®ã¿", value=True, key="j2")
    with col2:
        min_sold2 = st.number_input("æœ€ä½Soldæ•°", min_value=0, value=1, key="ms2")
    with col3:
        pages2 = st.number_input("æ¤œç´¢ãƒšãƒ¼ã‚¸æ•°", min_value=1, max_value=20, value=3, key="p2")

    extract_asin = st.toggle("ğŸ”— ASINæŠ½å‡ºï¼ˆAmazonæ¤œç´¢ãƒ»æ™‚é–“ã‹ã‹ã‚Šã¾ã™ï¼‰", value=False)

    if st.button("ğŸ” ã‚«ãƒ†ã‚´ãƒªæ¤œç´¢", key="btn2"):
        items_list2 = []
        progress2 = st.progress(0, text="æ¤œç´¢ä¸­...")

        for page in range(pages2):
            progress2.progress((page + 1) / pages2, text=f"ãƒšãƒ¼ã‚¸ {page+1}/{pages2}...")
            data = shopee_category_search(cat_id, page)
            raw = data.get("items", [])
            if not raw:
                break

            for item in raw:
                parsed = parse_item(item, japan_only2)
                if not parsed:
                    continue
                if parsed["sold"] < min_sold2:
                    continue
                items_list2.append(parsed)

            time.sleep(0.5)

        if extract_asin and items_list2:
            asin_progress = st.progress(0, text="ASINæŠ½å‡ºä¸­...")
            for i, item in enumerate(items_list2):
                asin_progress.progress((i + 1) / len(items_list2), text=f"ASINæŠ½å‡º {i+1}/{len(items_list2)}...")
                asin = search_asin(item["title"])
                item["asin"] = asin or ""
                item["amazon_url"] = f"https://www.amazon.co.jp/dp/{asin}" if asin else ""
                time.sleep(0.5)
            asin_progress.empty()

        progress2.empty()
        st.success(f"âœ… å•†å“æ•°: {len(items_list2)} ä»¶")

        if items_list2:
            df2 = pd.DataFrame(items_list2)
            cols = ["title", "item_url", "sold", "price", "is_preferred", "shop_name"]
            if extract_asin:
                cols += ["asin", "amazon_url"]
            df2 = df2[[c for c in cols if c in df2.columns]]
            df2.columns = ["ã‚¿ã‚¤ãƒˆãƒ«", "å•†å“URL", "Sold", "ä¾¡æ ¼(Â¥)", "Preferred", "åº—èˆ—å"] + (["ASIN", "AmazonURL"] if extract_asin else [])

            st.dataframe(df2, use_container_width=True)
            st.download_button(
                "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=to_csv(df2),
                file_name=f"shopee_category_{cat_label}.csv",
                mime="text/csv"
            )

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘¢ å°‚é–€åº—ãƒªã‚µãƒ¼ãƒ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab3:
    st.subheader("ğŸª Amazonä»•å…¥ã‚Œå°‚é–€åº—ã‚’æ¢ã™")

    mode3 = st.radio("å…¥åŠ›ãƒ¢ãƒ¼ãƒ‰", ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›", "CSVãƒãƒƒãƒï¼ˆè¤‡æ•°ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼‰"], horizontal=True)

    if mode3 == "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å…¥åŠ›":
        keyword3 = st.text_input("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆè‹±èªï¼‰", placeholder="ä¾‹: golf, swimming, toys", key="kw3")
        keywords3 = [keyword3] if keyword3 else []
    else:
        st.info("1è¡Œã«1ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆä¾‹: golf, swimming, toysï¼‰")
        csv_file = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«", type=["csv"])
        if csv_file:
            content = csv_file.read().decode("utf-8-sig")
            keywords3 = [row.strip() for row in content.split("\n") if row.strip()]
            st.write(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {len(keywords3)} ä»¶ â†’ {', '.join(keywords3[:5])}...")
        else:
            keywords3 = []

    col1, col2 = st.columns(2)
    with col1:
        max_cats = st.select_slider("æœ€å¤§ã‚«ãƒ†ã‚´ãƒªæ•°ï¼ˆå°‚é–€åº¦ï¼‰", options=[1, 2, 3, 4, 5], value=1)
        min_sold3 = st.number_input("æœ€ä½Soldæ•°", min_value=0, value=1, key="ms3")
    with col2:
        min_products3 = st.number_input("æœ€ä½å•†å“æ•°ï¼ˆ0=åˆ¶é™ãªã—ï¼‰", min_value=0, value=0, key="mp3")
        pages3 = st.number_input("æ¤œç´¢ãƒšãƒ¼ã‚¸æ•°", min_value=1, max_value=20, value=3, key="p3")

    col3, col4, col5 = st.columns(3)
    with col3:
        japan_only3 = st.toggle("ğŸ‡¯ğŸ‡µ æ—¥æœ¬ã‚»ãƒ©ãƒ¼ã®ã¿", value=True, key="j3")
    with col4:
        preferred_only3 = st.toggle("â­ Preferredã®ã¿", value=False, key="pref3")
    with col5:
        amazon_only = st.toggle("ğŸ“¦ Amazonä»•å…¥ã‚Œã®ã¿", value=True)

    if st.button("ğŸ” å°‚é–€åº—ãƒªã‚µãƒ¼ãƒé–‹å§‹", key="btn3"):
        if not keywords3:
            st.warning("ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        else:
            all_results = []

            for kw_idx, kw in enumerate(keywords3):
                st.write(f"ğŸ” **{kw}** ã‚’æ¤œç´¢ä¸­... ({kw_idx+1}/{len(keywords3)})")
                shops3 = {}
                progress3 = st.progress(0)

                for page in range(pages3):
                    progress3.progress((page + 1) / pages3)
                    data = shopee_search(kw, page)
                    raw = data.get("items", [])
                    if not raw:
                        break

                    for item in raw:
                        parsed = parse_item(item, japan_only3)
                        if not parsed:
                            continue
                        if parsed["sold"] < min_sold3:
                            continue
                        if preferred_only3 and not parsed["is_preferred"]:
                            continue

                        sid = parsed["shop_id"]
                        if sid not in shops3:
                            shops3[sid] = parsed

                    time.sleep(0.5)

                progress3.empty()

                # Check each shop
                checked = st.progress(0, text="åº—èˆ—ãƒã‚§ãƒƒã‚¯ä¸­...")
                shop_ids = list(shops3.keys())

                for i, sid in enumerate(shop_ids):
                    checked.progress((i + 1) / max(len(shop_ids), 1), text=f"åº—èˆ—ãƒã‚§ãƒƒã‚¯ {i+1}/{len(shop_ids)}...")
                    shop = shops3[sid]

                    # Get shop items to check categories & Amazon sourcing
                    items = get_shop_items(sid, page=0, limit=50)
                    if not items:
                        continue

                    # Category check (approximate using item data)
                    cat_ids = set()
                    amazon_count = 0
                    for it in items:
                        cats = it.get("categories", [])
                        if cats:
                            cat_ids.add(cats[0].get("catid", 0))
                        title = it.get("name", "")
                        if re.search(r'B0[A-Z0-9]{8}', title) or any(kw in title for kw in ["Amazon", "ã‚¢ãƒã‚¾ãƒ³"]):
                            amazon_count += 1

                    if len(cat_ids) > max_cats:
                        continue
                    if amazon_only and amazon_count < 1:
                        continue

                    # Get shop detail
                    info = get_shop_info(sid)

                    item_count = info.get("item_count", len(items))
                    if min_products3 > 0 and item_count < min_products3:
                        continue

                    all_results.append({
                        "æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰": kw,
                        "åº—èˆ—å": shop["shop_name"],
                        "åº—èˆ—URL": shop["shop_url"],
                        "Preferred": "â­ YES" if shop["is_preferred"] else "NO",
                        "ã‚«ãƒ†ã‚´ãƒªæ•°": len(cat_ids),
                        "å•†å“æ•°": item_count,
                        "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°": info.get("follower_count", 0),
                        "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°": info.get("rating_count", 0),
                        "è©•ä¾¡": round(info.get("rating_star", 0), 1),
                    })
                    time.sleep(0.3)

                checked.empty()

            st.success(f"âœ… å°‚é–€åº—: {len(all_results)} ä»¶è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

            if all_results:
                df3 = pd.DataFrame(all_results)
                st.dataframe(df3, use_container_width=True)
                st.download_button(
                    "ğŸ“¥ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=to_csv(df3),
                    file_name="shopee_specialist_shops.csv",
                    mime="text/csv"
                )
                st.info("ğŸ’¡ ã“ã®CSVã‚’â‘£ ASINæŠ½å‡ºã‚¿ãƒ–ã«èª­ã¿è¾¼ã¾ã›ã‚‹ã¨ã€å…¨å•†å“ã®ASINã‚’ä¸€æ‹¬æŠ½å‡ºã§ãã¾ã™")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# â‘£ ASINæŠ½å‡º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
with tab4:
    st.subheader("ğŸ”— åº—èˆ—ã®å…¨å•†å“ASINã‚’ä¸€æ‹¬æŠ½å‡º")

    st.info("â‘¢å°‚é–€åº—ãƒªã‚µãƒ¼ãƒã®CSVã‚’èª­ã¿è¾¼ã‚€ã€ã¾ãŸã¯URLã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„")

    input_mode4 = st.radio("å…¥åŠ›æ–¹æ³•", ["CSVã‹ã‚‰èª­è¾¼ï¼ˆâ‘¢ã®å‡ºåŠ›ï¼‰", "URLç›´æ¥å…¥åŠ›"], horizontal=True)

    shop_urls = []
    if input_mode4 == "CSVã‹ã‚‰èª­è¾¼ï¼ˆâ‘¢ã®å‡ºåŠ›ï¼‰":
        csv4 = st.file_uploader("CSVãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆåº—èˆ—URLåˆ—ãŒå¿…è¦ï¼‰", type=["csv"], key="csv4")
        if csv4:
            df_in = pd.read_csv(csv4)
            url_col = None
            for col in df_in.columns:
                if "URL" in col or "url" in col:
                    url_col = col
                    break
            if url_col:
                shop_urls = df_in[url_col].dropna().tolist()
                st.write(f"âœ… {len(shop_urls)} åº—èˆ—ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.write(shop_urls[:5])
            else:
                st.error("ã€ŒURLã€ã‚’å«ã‚€åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        urls_text = st.text_area("åº—èˆ—URLï¼ˆ1è¡Œ1URLï¼‰", placeholder="https://shopee.co.jp/shopname1\nhttps://shopee.co.jp/shopname2", height=150)
        shop_urls = [u.strip() for u in urls_text.split("\n") if u.strip()]

    if shop_urls:
        st.write(f"å¯¾è±¡åº—èˆ—æ•°: **{len(shop_urls)}** ä»¶")

    if st.button("ğŸ” ASINä¸€æ‹¬æŠ½å‡ºé–‹å§‹", key="btn4") and shop_urls:
        all_asins = []
        total_progress = st.progress(0, text="ASINæŠ½å‡ºä¸­...")

        for shop_idx, shop_url in enumerate(shop_urls):
            shop_name = shop_url.rstrip("/").split("/")[-1]
            st.write(f"ğŸ“¦ **{shop_name}** ã®å•†å“ã‚’å–å¾—ä¸­...")

            # Get shop ID from search (simplified)
            page = 0
            shop_items = []
            while True:
                # Try to get items via recommendation API
                # Need shop_id - extract from search
                data = shopee_search(shop_name, 0)
                raw = data.get("items", [])
                found_id = None
                for it in raw:
                    basic = it.get("item_basic", {})
                    if basic.get("shop_name", "") == shop_name:
                        found_id = basic.get("shopid")
                        break
                if found_id:
                    items = get_shop_items(found_id, page=page, limit=100)
                    if not items:
                        break
                    shop_items.extend(items)
                    page += 1
                    if page > 5:
                        break
                    time.sleep(0.5)
                else:
                    break

            item_progress = st.progress(0, text=f"{shop_name}: ASINæ¤œç´¢ä¸­...")
            for i, item in enumerate(shop_items):
                item_progress.progress((i + 1) / max(len(shop_items), 1))
                title = item.get("name", "")
                asin = search_asin(title)

                all_asins.append({
                    "åº—èˆ—å": shop_name,
                    "åº—èˆ—URL": shop_url,
                    "ã‚¿ã‚¤ãƒˆãƒ«": title,
                    "å•†å“URL": f"{SHOPEE_BASE}/{shop_name}-i.{item.get('shopid','')}.{item.get('itemid','')}",
                    "Sold": item.get("historical_sold", 0),
                    "ä¾¡æ ¼(Â¥)": item.get("price", 0) / 100000,
                    "ASIN": asin or "",
                    "Amazon URL": f"https://www.amazon.co.jp/dp/{asin}" if asin else "",
                })
                time.sleep(0.5)

            item_progress.empty()
            total_progress.progress((shop_idx + 1) / len(shop_urls))

        total_progress.empty()

        asin_found = len([a for a in all_asins if a["ASIN"]])
        st.success(f"âœ… å•†å“æ•°: {len(all_asins)} ä»¶ / ASINå–å¾—: {asin_found} ä»¶")

        if all_asins:
            df4 = pd.DataFrame(all_asins)
            st.dataframe(df4, use_container_width=True)
            st.download_button(
                "ğŸ“¥ ASIN CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=to_csv(df4),
                file_name="shopee_asins.csv",
                mime="text/csv"
            )

# Footer
st.markdown("---")
st.markdown(
    "<p style='text-align:center; color:#4a5568; font-size:0.75rem;'>Shopee Research Tool â€” For personal use only. Please respect Shopee's Terms of Service.</p>",
    unsafe_allow_html=True
)
